{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISMB figures notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/vae_cox`\n"
     ]
    }
   ],
   "source": [
    "\n",
    "include(\"engines/init.jl\")\n",
    "include(\"engines/data_processing.jl\")\n",
    "include(\"engines/deep_learning.jl\")\n",
    "include(\"engines/cross_validation.jl\")\n",
    "outpath, session_id = set_dirs() ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BRCA = MLSurvDataset(\"Data/TCGA_BRCA_tpm_n1049_btypes_labels_surv.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLSurvDataset(Float32[0.008600163 0.0 … 0.0 0.0; 0.033423774 0.00432137 … 0.0 0.029383799; … ; 0.4828736 0.0 … 0.0 0.15836251; 0.045322984 0.017033324 … 0.0 0.20682588], [\"01H001\", \"02H003\", \"02H009\", \"02H017\", \"02H026\", \"02H033\", \"02H053\", \"02H066\", \"03H016\", \"03H022\"  …  \"13H186\", \"14H001\", \"14H007\", \"14H012\", \"14H015\", \"14H017\", \"14H019\", \"14H020\", \"14H023\", \"14H038\"], [\"TSPAN6\", \"TNMD\", \"DPM1\", \"SCYL3\", \"C1orf112\", \"FGR\", \"CFH\", \"FUCA2\", \"GCLC\", \"NFYA\"  …  \"AP003086.3\", \"AL109627.1\", \"AC084851.4\", \"AC024558.2\", \"AC108479.4\", \"AL512357.2\", \"AL138899.3\", \"AL669830.1\", \"AC091135.2\", \"AL357075.5\"], [\"lncRNA\", \"lncRNA\", \"protein_coding\", \"lncRNA\", \"protein_coding\", \"lncRNA\", \"protein_coding,retained_intron\", \"lncRNA\", \"protein_coding\", \"protein_coding\"  …  \"transcribed_processed_pseudogene\", \"lncRNA\", \"processed_pseudogene\", \"protein_coding\", \"unprocessed_pseudogene\", \"lncRNA\", \"protein_coding\", \"retained_intron\", \"unprocessed_pseudogene\", \"protein_coding\"], [\"Therapy-related myeloid neoplasms\", \"AML with minimal differentiation\", \"AML without maturation\", \"AML with minimal differentiation\", \"AML with myelodysplasia-related changes\", \"Acute monoblastic and monocytic leukaemia\", \"AML without maturation\", \"AML without maturation\", \"Acute monoblastic and monocytic leukaemia\", \"AML with myelodysplasia-related changes\"  …  \"Acute myelomonocytic leukaemia\", \"AML without maturation\", \"AML with maturation\", \"AML with minimal differentiation\", \"Acute myelomonocytic leukaemia\", \"AML without maturation\", \"AML with minimal differentiation\", \"AML without maturation\", \"AML with myelodysplasia-related changes\", \"AML with inv(3)(q21q26.2) or t(3;3)(q21;q26.2); RPN1-EVI1\"], [2170, 1396, 236, 284, 358, 101, 37, 135, 6033, 805  …  150, 2086, 75, 1467, 207, 213, 1983, 1952, 36, 255], [1, 1, 1, 1, 1, 1, 1, 1, 0, 1  …  1, 0, 1, 1, 1, 1, 0, 0, 1, 1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LAML = MLSurvDataset(\"Data/LGN_AML_tpm_n300_btypes_labels_surv.h5\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "format_train_test (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function format_train_test(fold; device = gpu)\n",
    "    nsamples = size(fold[\"train_x\"])[1]\n",
    "    ordering = sortperm(-fold[\"Y_t_train\"])\n",
    "    train_x = device(Matrix(fold[\"train_x\"][ordering,:]'));\n",
    "    train_y_t = device(Matrix(fold[\"Y_t_train\"][ordering,:]'));\n",
    "    train_y_e = device(Matrix(fold[\"Y_e_train\"][ordering,:]'));\n",
    "    NE_frac_tr = sum(train_y_e .== 1) != 0 ? 1 / sum(train_y_e .== 1) : 0\n",
    "\n",
    "    nsamples = size(fold[\"test_x\"])[1]\n",
    "    ordering = sortperm(-fold[\"Y_t_test\"])\n",
    "    test_x = device(Matrix(fold[\"test_x\"][ordering,:]'));\n",
    "    test_y_t = device(Matrix(fold[\"Y_t_test\"][ordering,:]'));\n",
    "    test_y_e = device(Matrix(fold[\"Y_e_test\"][ordering,:]'));\n",
    "    NE_frac_tst = sum(test_y_e .== 1) != 0 ? 1 / sum(test_y_e .== 1) : 0\n",
    "    return train_x, train_y_t, train_y_e, NE_frac_tr, test_x, test_y_t, test_y_e, NE_frac_tst\n",
    "end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb genes : 14996\n",
      "nb patients : 300\n",
      "% uncensored : 0.7433333333333333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dict{String, Any} with 3 entries:\n",
       "  \"cph\"  => Chain(Dense(125 => 64, leakyrelu), Dense(64 => 64, leakyrelu), Dens…\n",
       "  \"venc\" => VariationalEncoder(Dense(14996 => 128, leakyrelu), Dense(128 => 125…\n",
       "  \"vdec\" => Chain(Dense(125 => 128, leakyrelu), Dense(128 => 14996))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "function data_prep(DATA;nfolds = 5, nepochs =1000, dim_redux= 125)\n",
    "    keep = [occursin(\"protein_coding\", bt) for bt in DATA.biotypes]\n",
    "    println(\"nb genes : $(sum(keep))\")\n",
    "    println(\"nb patients : $(size(DATA.samples)[1])\")\n",
    "    println(\"% uncensored : $(mean(DATA.surve .!= 0))\")\n",
    "    params_dict = Dict(\n",
    "            ## run infos \n",
    "            \"session_id\" => session_id, \"nfolds\" =>5,  \"modelid\" => \"$(bytes2hex(sha256(\"$(now())\"))[1:Int(floor(end/3))])\",\n",
    "            \"machine_id\"=>strip(read(`hostname`, String)), \"device\" => \"$(device())\", \"model_title\"=>\"AECPHDNN\",\n",
    "            ## data infos \n",
    "            \"dataset\" => \"BRCA_data(norm=true)\", \"nsamples\" => size(DATA.samples)[1],\n",
    "            \"nsamples_test\" => Int(round(size(DATA.samples)[1] / nfolds)), \"ngenes\" => size(DATA.genes[keep])[1],\n",
    "            \"nsamples_train\" => size(DATA.samples)[1] - Int(round(size(DATA.samples)[1] / nfolds)),\n",
    "            ## optim infos \n",
    "            \"nepochs\" => nepochs, \"ae_lr\" =>1e-6, \"cph_lr\" => 1e-5, \"ae_wd\" => 1e-6, \"cph_wd\" => 1e-4,\n",
    "            ## model infos\n",
    "            \"model_type\"=> \"vaecox\", \"dim_redux\" => dim_redux, \"ae_nb_hls\" => 2,\n",
    "            \"enc_nb_hl\" => 2, \"enc_hl_size\"=> 128,\n",
    "            \"venc_nb_hl\" => 2, \"venc_hl_size\"=> 128,  \"dec_nb_hl\" => 2 , \"dec_hl_size\"=> 128,\n",
    "            \"nb_clinf\" => 0, \"cph_nb_hl\" => 2, \"cph_hl_size\" => 64, \n",
    "            \"insize\" => size(DATA.genes[keep])[1],\n",
    "            ## metrics\n",
    "            \"model_cv_complete\" => false\n",
    "        )\n",
    "    # split train test\n",
    "    folds = split_train_test(Matrix(DATA.data[:,keep]), DATA.survt, DATA.surve, DATA.samples;nfolds =5)\n",
    "    fold = folds[1]\n",
    "    # format input data  \n",
    "    train_x, train_y_t, train_y_e, NE_frac_tr, test_x, test_y_t, test_y_e, NE_frac_tst = format_train_test(fold)\n",
    "\n",
    "    return train_x, train_y_t, train_y_e, NE_frac_tr, test_x, test_y_t, test_y_e, NE_frac_tst, params_dict\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cox_nll_vec (generic function with 6 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function cox_nll_vec(mdl::Chain, X_, Y_e_, NE_frac)\n",
    "    outs = vec(mdl(X_))\n",
    "    #outs = vec(mdl.cphdnn(mdl.encoder(X_)))\n",
    "    hazard_ratios = exp.(outs)\n",
    "    log_risk = log.(cumsum(hazard_ratios))\n",
    "    uncensored_likelihood = outs .- log_risk\n",
    "    censored_likelihood = uncensored_likelihood .* Y_e_'\n",
    "    #neg_likelihood = - sum(censored_likelihood) / sum(e .== 1)\n",
    "    neg_likelihood = - sum(censored_likelihood) * NE_frac\n",
    "    return neg_likelihood\n",
    "end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE_COX_loss (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function VAE_COX_loss(VENC, CPH, X, Y_e, NE_frac;device = gpu)\n",
    "    mu, log_sigma = VENC(X)\n",
    "    #z = mu + device(randn(Float32, size(log_sigma))) .* exp.(log_sigma)\n",
    "    outs = vec(CPH(mu))\n",
    "    hazard_ratios = exp.(outs)\n",
    "    log_risk = log.(cumsum(hazard_ratios))\n",
    "    uncensored_likelihood = outs .- log_risk\n",
    "    censored_likelihood = uncensored_likelihood .* Y_e'\n",
    "    #neg_likelihood = - sum(censored_likelihood) / sum(e .== 1)\n",
    "    neg_likelihood = - sum(censored_likelihood) * NE_frac\n",
    "    return neg_likelihood\n",
    "end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb genes : 14996\n",
      "nb patients : 300\n",
      "% uncensored : 0.7433333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 TRAIN 6381.789 cind: 0.51 \t TEST cind: 0.532 [856, 752, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 TRAIN 5533.772 cind: 0.754 \t TEST cind: 0.68 [1093, 515, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 TRAIN 4794.221 cind: 0.781 \t TEST cind: 0.688 [1107, 501, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 TRAIN 4154.814 cind: 0.8 \t TEST cind: 0.7 [1125, 483, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 TRAIN 3601.228 cind: 0.812 \t TEST cind: 0.7 [1126, 482, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 TRAIN 3121.794 cind: 0.817 \t TEST cind: 0.706 [1136, 472, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 TRAIN 2706.696 cind: 0.818 \t TEST cind: 0.705 [1134, 474, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700 TRAIN 2347.575 cind: 0.817 \t TEST cind: 0.707 [1137, 471, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800 TRAIN 2037.22 cind: 0.817 \t TEST cind: 0.71 [1142, 466, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900 TRAIN 1769.359 cind: 0.816 \t TEST cind: 0.711 [1143, 465, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 TRAIN 1538.514 cind: 0.814 \t TEST cind: 0.712 [1145, 463, 0]\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y_t, train_y_e, NE_frac_tr, test_x, test_y_t, test_y_e, NE_frac_tst, params_dict = data_prep(LAML)\n",
    "# create model \n",
    "#model = build_vaecox(params_dict)\n",
    "cphdnn = gpu(Chain(Dense(size(train_x)[1], 3040, leakyrelu), Dense(3040, 616, leakyrelu), Dense(616,125), Dense(125,64, leakyrelu),Dense(64, 1, bias = false)))\n",
    "opt = Flux.ADAM(1e-5)\n",
    "wd = 1#params_dict[\"cph_wd\"]\n",
    "for i in 1:1000\n",
    "    ps1 = Flux.params(cphdnn)\n",
    "    gs1 = gradient(ps1) do \n",
    "        cox_nll_vec(cphdnn, train_x, train_y_e, NE_frac_tr) + l2_penalty(cphdnn) * wd\n",
    "        #VAE_COX_loss(model[\"venc\"], model[\"cph\"], train_x, train_y_e, NE_frac_tr) + l2_penalty(model[\"venc\"]) * wd + l2_penalty(model[\"cph\"]) * wd \n",
    "    end \n",
    "    cphloss = round(cox_nll_vec(cphdnn, train_x, train_y_e, NE_frac_tr) + l2_penalty(cphdnn) * wd, digits = 3)\n",
    "    #cphloss = round(VAE_COX_loss(model[\"venc\"], model[\"cph\"], train_x, train_y_e, NE_frac_tr) + l2_penalty(model[\"venc\"]) * wd + l2_penalty(model[\"cph\"]) * wd , digits = 3)\n",
    "    #OUTS_tr = model[\"cph\"](model[\"venc\"](train_x)[1])\n",
    "    #OUTS_tst =  model[\"cph\"](model[\"venc\"](test_x)[1])\n",
    "    OUTS_tr = cphdnn(train_x)\n",
    "    OUTS_tst = cphdnn(test_x)\n",
    "    cind_tr, cdnt_tr, ddnt_tr, tied_tr  = concordance_index(train_y_t, train_y_e, -1 * OUTS_tr)\n",
    "    cind_test,cdnt_tst, ddnt_tst, tied_tst = concordance_index(test_y_t, test_y_e, -1 *OUTS_tst)\n",
    "    \n",
    "    if i%100==0 || i == 1\n",
    "    println(\"$i TRAIN $cphloss cind: $(round(cind_tr, digits = 3)) \\t TEST cind: $(round(cind_test, digits = 3)) [$(Int(cdnt_tst)), $(Int(ddnt_tst)), $(Int(tied_tst))]\")\n",
    "    end \n",
    "    Flux.update!(opt,ps1, gs1)\n",
    "end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTS_tr = cphdnn(train_x)\n",
    "OUTS_tst = cphdnn(test_x)\n",
    "params_dict[\"cph_tst_c_ind\"] = concordance_index(test_y_t, test_y_e, -1 * OUTS_tst)[1]\n",
    "params_dict[\"cph_train_c_ind\"] = concordance_index(train_y_t, train_y_e, -1 * OUTS_tr)[1]\n",
    "model_params_path = \"$(params_dict[\"session_id\"])/$(params_dict[\"model_type\"])_$(params_dict[\"modelid\"])\"\n",
    "mkdir(\"RES/$model_params_path\")\n",
    "bson(\"RES/$model_params_path/params.bson\",params_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cphdnn = gpu(Chain(Dense(size(DATA.data[:,keep])[2], 64, leakyrelu), Dense(64, 64,leakyrelu),Dense(64, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y_t, train_y_e, NE_frac_tr, test_x, test_y_t, test_y_e, NE_frac_tst = format_train_test(fold)\n",
    "cphdnn(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function validate_vaecox(DATA, params_dict;device = gpu)\n",
    "    nfolds, nepochs, dim_redux = 5, 1000, 125\n",
    "    keep = [occursin(\"protein_coding\", bt) for bt in DATA.biotypes]\n",
    "    # split train test\n",
    "    folds = split_train_test(Matrix(DATA.data[:,keep]), DATA.survt, DATA.surve, DATA.samples;nfolds =5)\n",
    "    fold = folds[1]\n",
    "\n",
    "    venc = VariationalEncoder(size(DATA.data[:,keep])[2], 125, 600)\n",
    "    vdec = Decoder(size(DATA.data[:,keep])[2], 125, 600)\n",
    "    VAE_opt = Flux.ADAM(1e-4)\n",
    "\n",
    "    cphdnn = device(Chain(Dense(size(DATA.data[:,keep])[2], 125, leakyrelu), Dense(125, 100,leakyrelu),Dense(100, 1)))\n",
    "    cphdnn_opt = Flux.ADAM(1e-5)\n",
    "\n",
    "    train_x, train_y_t, train_y_e, NE_frac_tr, test_x, test_y_t, test_y_e, NE_frac_tst = format_train_test(fold)\n",
    "    for i in 1:nepochs\n",
    "        ps1 = Flux.params(venc, vdec)\n",
    "        gs1 = gradient(ps1) do\n",
    "            VAE_lossf(venc, vdec, train_x)\n",
    "        end \n",
    "        VAE_loss = VAE_lossf(venc, vdec, train_x)\n",
    "        VAE_cor = round(my_cor(vec(train_x), vec(MyReconstruct(venc, vdec, train_x)[end])),digits = 3)\n",
    "        VAE_test = round(my_cor(vec(test_x), vec(MyReconstruct(venc, vdec, test_x)[end])),digits = 3)\n",
    "\n",
    "        ps2 = Flux.params(venc, cphdnn)\n",
    "        gs2 = gradient(ps2) do \n",
    "            cox_nll_vec(cphdnn, train_x, train_y_e, NE_frac_tr)\n",
    "            #VAE_COX_loss(venc, cphdnn, train_x, train_y_e, NE_frac_tr)\n",
    "        end \n",
    "        CPH_loss = round(cox_nll_vec(cphdnn, train_x, train_y_e, NE_frac_tr), digits = 3) #round(VAE_COX_loss(venc, cphdnn, train_x, train_y_e, NE_frac_tr), digits = 3)\n",
    "        #mu, log_sigma = venc(train_x)\n",
    "        #z = mu + device(randn(Float32, size(log_sigma))) .* exp.(log_sigma)\n",
    "        #OUTS_tr = vec(cphdnn(z))\n",
    "        OUTS_tr = cphdnn(train_x)\n",
    "        OUTS_tst =  cphdnn(test_x)\n",
    "        cind_tr, cdnt_tr, ddnt_tr, tied_tr  = concordance_index(train_y_t, train_y_e, OUTS_tr)\n",
    "        cind_test,cdnt_tst, ddnt_tst, tied_tst = concordance_index(test_y_t, test_y_e,OUTS_tst)\n",
    "        #Flux.update!(VAE_opt, ps1, gs1)\n",
    "        Flux.update!(cphdnn_opt, ps2, gs2)\n",
    "        if i % 100 == 0 || i == 1\n",
    "            println(\"$i TRAIN - VAE-loss-avg: $VAE_loss\\tVAE-cor: $VAE_cor CPH-loss: $CPH_loss CPH-cind: $(round(cind_tr,digits=3))\")\n",
    "            println(\"$i TEST - VAE-loss-avg: $VAE_test \\tVAE-cor: CPH-loss: CPH-cind: $(round(cind_test,digits=3)) [$(Int(cdnt_tst)), $(Int(ddnt_tst)), $(Int(tied_tst))]\")\n",
    "\n",
    "        end\n",
    "    end\n",
    "    return cphdnn\n",
    "end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdnn = validate_vaecox(DATA, params_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdnn(DATA.data[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb genes : 14996\n",
      "nb patients : 300\n",
      "% uncensored : 0.7433333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1\t TRAIN AE-loss 0.994 \t AE-cor: 0.008\t cph-loss-avg: 0.020545 \t cph-cind: 0.611\n",
      "\t\tTEST AE-loss 0.991 \t AE-cor: 0.006\t cph-loss-avg: 0.058383 \t cph-cind: 0.515 [836, 788, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 100\t TRAIN AE-loss 0.972 \t AE-cor: 0.004\t cph-loss-avg: 0.019126 \t cph-cind: 0.827\n",
      "\t\tTEST AE-loss 0.97 \t AE-cor: 0.002\t cph-loss-avg: 0.0563 \t cph-cind: 0.657 [1067, 557, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 200\t TRAIN AE-loss 0.969 \t AE-cor: 0.004\t cph-loss-avg: 0.018949 \t cph-cind: 0.863\n",
      "\t\tTEST AE-loss 0.967 \t AE-cor: 0.002\t cph-loss-avg: 0.056367 \t cph-cind: 0.646 [1049, 575, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 300\t TRAIN AE-loss 0.966 \t AE-cor: 0.004\t cph-loss-avg: 0.018913 \t cph-cind: 0.875\n",
      "\t\tTEST AE-loss 0.965 \t AE-cor: 0.002\t cph-loss-avg: 0.0564 \t cph-cind: 0.643 [1045, 579, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 400\t TRAIN AE-loss 0.964 \t AE-cor: 0.004\t cph-loss-avg: 0.018904 \t cph-cind: 0.881\n",
      "\t\tTEST AE-loss 0.963 \t AE-cor: 0.002\t cph-loss-avg: 0.056483 \t cph-cind: 0.638 [1036, 588, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 500\t TRAIN AE-loss 0.963 \t AE-cor: 0.005\t cph-loss-avg: 0.018899 \t cph-cind: 0.883\n",
      "\t\tTEST AE-loss 0.962 \t AE-cor: 0.003\t cph-loss-avg: 0.05645 \t cph-cind: 0.638 [1036, 588, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 600\t TRAIN AE-loss 0.962 \t AE-cor: 0.005\t cph-loss-avg: 0.018898 \t cph-cind: 0.884\n",
      "\t\tTEST AE-loss 0.961 \t AE-cor: 0.003\t cph-loss-avg: 0.056433 \t cph-cind: 0.639 [1037, 587, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 700\t TRAIN AE-loss 0.962 \t AE-cor: 0.005\t cph-loss-avg: 0.018897 \t cph-cind: 0.886\n",
      "\t\tTEST AE-loss 0.96 \t AE-cor: 0.004\t cph-loss-avg: 0.056417 \t cph-cind: 0.638 [1036, 588, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 800\t TRAIN AE-loss 0.962 \t AE-cor: 0.005\t cph-loss-avg: 0.018899 \t cph-cind: 0.887\n",
      "\t\tTEST AE-loss 0.96 \t AE-cor: 0.004\t cph-loss-avg: 0.056417 \t cph-cind: 0.641 [1041, 583, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 900\t TRAIN AE-loss 0.961 \t AE-cor: 0.005\t cph-loss-avg: 0.018896 \t cph-cind: 0.889\n",
      "\t\tTEST AE-loss 0.96 \t AE-cor: 0.004\t cph-loss-avg: 0.0564 \t cph-cind: 0.64 [1039, 585, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1000\t TRAIN AE-loss 0.961 \t AE-cor: 0.005\t cph-loss-avg: 0.018893 \t cph-cind: 0.892\n",
      "\t\tTEST AE-loss 0.96 \t AE-cor: 0.004\t cph-loss-avg: 0.0564 \t cph-cind: 0.64 [1040, 584, 0]\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y_t, train_y_e, NE_frac_tr, test_x, test_y_t, test_y_e, NE_frac_tst, params_dict = data_prep(LAML)\n",
    "# create model \n",
    "model = build_aecox(params_dict)\n",
    "for iter in 1:params_dict[\"nepochs\"]\n",
    "    ps1 = Flux.params(model[\"cph\"].model, model[\"enc\"])\n",
    "    gs1 = gradient(ps1) do\n",
    "        model[\"cph\"].lossf(model[\"cph\"],model[\"enc\"], train_x, train_y_e, NE_frac_tr, params_dict[\"cph_wd\"])\n",
    "    end \n",
    "    ## gradient Auto-Encoder \n",
    "    ps2 = Flux.params(model[\"ae\"].net)\n",
    "    gs2 = gradient(ps2) do\n",
    "        model[\"ae\"].lossf(model[\"ae\"], train_x, train_x, weight_decay = params_dict[\"ae_wd\"])\n",
    "    end\n",
    "    Flux.update!(model[\"cph\"].opt, ps1, gs1)\n",
    "    #Flux.update!(model[\"ae\"].opt, ps2, gs2)\n",
    "\n",
    "    ######\n",
    "    OUTS_tr = vec(model[\"cph\"].model(model[\"enc\"](train_x)))\n",
    "    ae_loss = model[\"ae\"].lossf(model[\"ae\"], train_x, train_x, weight_decay = params_dict[\"ae_wd\"])\n",
    "    ae_cor =  round(my_cor(vec(train_x), vec(model[\"ae\"].net(train_x))),digits = 3)\n",
    "    cph_loss = model[\"cph\"].lossf(model[\"cph\"],model[\"enc\"](train_x), train_y_e, NE_frac_tr, params_dict[\"cph_wd\"])\n",
    "    ae_loss_test = round(model[\"ae\"].lossf(model[\"ae\"], test_x, test_x, weight_decay = params_dict[\"ae_wd\"]), digits = 3)\n",
    "    ae_cor_test = round(my_cor(vec(test_x), vec(model[\"ae\"].net(test_x))), digits= 3)\n",
    "    cph_loss_test = round(model[\"cph\"].lossf(model[\"cph\"],model[\"enc\"](test_x), test_y_e, NE_frac_tst, params_dict[\"cph_wd\"]), digits= 3)\n",
    "                    \n",
    "    OUTS_tst =  vec(model[\"cph\"].model(model[\"enc\"](test_x)))\n",
    "            \n",
    "    cind_tr, cdnt_tr, ddnt_tr, tied_tr  = concordance_index(train_y_t, train_y_e, OUTS_tr)\n",
    "    cind_test,cdnt_tst, ddnt_tst, tied_tst = concordance_index(test_y_t, test_y_e,OUTS_tst)\n",
    "    if iter % 100 == 0  || iter == 1     \n",
    "        println(\"FOLD $iter\\t TRAIN AE-loss $(round(ae_loss,digits =3)) \\t AE-cor: $(round(ae_cor, digits = 3))\\t cph-loss-avg: $(round(cph_loss / params_dict[\"nsamples_train\"],digits =6)) \\t cph-cind: $(round(cind_tr,digits =3))\")\n",
    "        println(\"\\t\\tTEST AE-loss $(round(ae_loss_test,digits =3)) \\t AE-cor: $(round(ae_cor_test, digits = 3))\\t cph-loss-avg: $(round(cph_loss_test / params_dict[\"nsamples_test\"],digits =6)) \\t cph-cind: $(round(cind_test,digits =3)) [$(Int(cdnt_tst)), $(Int(ddnt_tst)), $(Int(tied_tst))]\")\n",
    "    end\n",
    "    params_dict[\"cph_tst_c_ind\"] = concordance_index(test_y_t, test_y_e, OUTS_tst)[1]\n",
    "    params_dict[\"cph_train_c_ind\"] = concordance_index(train_y_t, train_y_e, OUTS_tr)[1]\n",
    "    params_dict[\"step\"] = iter \n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AE_model(Chain(Dense(14996 => 3040, leakyrelu), Dense(3040 => 616, leakyrelu), Dense(616 => 125), Dense(125 => 616, leakyrelu), Dense(616 => 3040, leakyrelu), Dense(3040 => 14996, leakyrelu)), Chain(Dense(14996 => 3040, leakyrelu), Dense(3040 => 616, leakyrelu), Dense(616 => 125)), Chain(Dense(125 => 616, leakyrelu), Dense(616 => 3040, leakyrelu), Dense(3040 => 14996, leakyrelu)), Dense(3040 => 14996, leakyrelu), Adam(1.0e-6, (0.9, 0.999), 1.0e-8, IdDict{Any, Any}()), mse_l2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = build_aecox(params_dict)\n",
    "model[\"ae\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#params_dict[\"cph_tst_c_ind\"] = concordance_index(test_y_t, test_y_e, OUTS_tst)[1]\n",
    "#params_dict[\"cph_train_c_ind\"] = concordance_index(train_y_t, train_y_e, OUTS_tr)[1]\n",
    "#params_dict[\"ae_tst_corr\"] = my_cor(ae_outs_test, x_test)\n",
    "#params_dict[\"ae_train_corr\"] = my_cor(ae_outs_train, x_train)\n",
    "\n",
    "#params_dict[\"model_cv_complete\"] = true\n",
    "model_params_path = \"$(params_dict[\"session_id\"])/$(params_dict[\"model_type\"])_$(params_dict[\"modelid\"])\"\n",
    "mkdir(\"RES/$model_params_path\")\n",
    "bson(\"RES/$model_params_path/params.bson\",params_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figures  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>41 rows × 33 columns (omitted printing of 25 columns)</p><table class=\"data-frame\"><thead><tr><th></th><th>ae_lr</th><th>dim_redux</th><th>ae_nb_hls</th><th>nsamples</th><th>cph_wd</th><th>cph_hl_size</th><th>nepochs</th><th>venc_nb_hl</th></tr><tr><th></th><th title=\"Float64\">Float64</th><th title=\"Int64\">Int64</th><th title=\"Int64\">Int64</th><th title=\"Int64\">Int64</th><th title=\"Float64\">Float64</th><th title=\"Int64\">Int64</th><th title=\"Int64\">Int64</th><th title=\"Int64\">Int64</th></tr></thead><tbody><tr><th>1</th><td>1.0e-6</td><td>125</td><td>2</td><td>300</td><td>0.0001</td><td>64</td><td>1000</td><td>2</td></tr><tr><th>2</th><td>1.0e-6</td><td>125</td><td>2</td><td>300</td><td>0.0001</td><td>64</td><td>2000</td><td>2</td></tr><tr><th>3</th><td>1.0e-6</td><td>125</td><td>2</td><td>300</td><td>0.0001</td><td>64</td><td>2000</td><td>2</td></tr><tr><th>4</th><td>1.0e-6</td><td>125</td><td>2</td><td>300</td><td>0.0001</td><td>64</td><td>2000</td><td>2</td></tr><tr><th>5</th><td>1.0e-6</td><td>125</td><td>2</td><td>300</td><td>0.0001</td><td>64</td><td>2000</td><td>2</td></tr><tr><th>6</th><td>1.0e-6</td><td>125</td><td>2</td><td>300</td><td>0.0001</td><td>64</td><td>2000</td><td>2</td></tr><tr><th>7</th><td>1.0e-6</td><td>125</td><td>2</td><td>300</td><td>0.0001</td><td>64</td><td>2000</td><td>2</td></tr><tr><th>8</th><td>1.0e-6</td><td>125</td><td>2</td><td>300</td><td>0.0001</td><td>64</td><td>2000</td><td>2</td></tr><tr><th>9</th><td>1.0e-6</td><td>125</td><td>2</td><td>300</td><td>0.0001</td><td>64</td><td>2000</td><td>2</td></tr><tr><th>10</th><td>1.0e-6</td><td>125</td><td>2</td><td>300</td><td>0.0001</td><td>64</td><td>2000</td><td>2</td></tr><tr><th>11</th><td>1.0e-6</td><td>125</td><td>2</td><td>300</td><td>0.0001</td><td>64</td><td>2000</td><td>2</td></tr><tr><th>12</th><td>1.0e-6</td><td>125</td><td>2</td><td>300</td><td>0.0001</td><td>64</td><td>2000</td><td>2</td></tr><tr><th>13</th><td>1.0e-6</td><td>125</td><td>2</td><td>300</td><td>0.0001</td><td>64</td><td>2000</td><td>2</td></tr><tr><th>14</th><td>1.0e-6</td><td>125</td><td>2</td><td>300</td><td>0.0001</td><td>64</td><td>2000</td><td>2</td></tr><tr><th>15</th><td>1.0e-6</td><td>125</td><td>2</td><td>300</td><td>0.0001</td><td>64</td><td>2000</td><td>2</td></tr><tr><th>16</th><td>1.0e-6</td><td>125</td><td>2</td><td>300</td><td>0.0001</td><td>64</td><td>2000</td><td>2</td></tr><tr><th>17</th><td>1.0e-6</td><td>125</td><td>2</td><td>300</td><td>0.0001</td><td>64</td><td>2000</td><td>2</td></tr><tr><th>18</th><td>1.0e-6</td><td>125</td><td>2</td><td>300</td><td>0.0001</td><td>64</td><td>2000</td><td>2</td></tr><tr><th>19</th><td>1.0e-6</td><td>125</td><td>2</td><td>300</td><td>0.0001</td><td>64</td><td>2000</td><td>2</td></tr><tr><th>20</th><td>1.0e-6</td><td>125</td><td>2</td><td>300</td><td>0.0001</td><td>64</td><td>2000</td><td>2</td></tr><tr><th>21</th><td>1.0e-6</td><td>125</td><td>2</td><td>300</td><td>0.0001</td><td>64</td><td>2000</td><td>2</td></tr><tr><th>22</th><td>1.0e-6</td><td>125</td><td>2</td><td>300</td><td>0.0001</td><td>64</td><td>2000</td><td>2</td></tr><tr><th>23</th><td>1.0e-6</td><td>125</td><td>2</td><td>300</td><td>0.0001</td><td>64</td><td>2000</td><td>2</td></tr><tr><th>24</th><td>1.0e-6</td><td>125</td><td>2</td><td>300</td><td>0.0001</td><td>64</td><td>2000</td><td>2</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccccc}\n",
       "\t& ae\\_lr & dim\\_redux & ae\\_nb\\_hls & nsamples & cph\\_wd & cph\\_hl\\_size & nepochs & venc\\_nb\\_hl & \\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Int64 & Int64 & Int64 & Float64 & Int64 & Int64 & Int64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 1.0e-6 & 125 & 2 & 300 & 0.0001 & 64 & 1000 & 2 & $\\dots$ \\\\\n",
       "\t2 & 1.0e-6 & 125 & 2 & 300 & 0.0001 & 64 & 2000 & 2 & $\\dots$ \\\\\n",
       "\t3 & 1.0e-6 & 125 & 2 & 300 & 0.0001 & 64 & 2000 & 2 & $\\dots$ \\\\\n",
       "\t4 & 1.0e-6 & 125 & 2 & 300 & 0.0001 & 64 & 2000 & 2 & $\\dots$ \\\\\n",
       "\t5 & 1.0e-6 & 125 & 2 & 300 & 0.0001 & 64 & 2000 & 2 & $\\dots$ \\\\\n",
       "\t6 & 1.0e-6 & 125 & 2 & 300 & 0.0001 & 64 & 2000 & 2 & $\\dots$ \\\\\n",
       "\t7 & 1.0e-6 & 125 & 2 & 300 & 0.0001 & 64 & 2000 & 2 & $\\dots$ \\\\\n",
       "\t8 & 1.0e-6 & 125 & 2 & 300 & 0.0001 & 64 & 2000 & 2 & $\\dots$ \\\\\n",
       "\t9 & 1.0e-6 & 125 & 2 & 300 & 0.0001 & 64 & 2000 & 2 & $\\dots$ \\\\\n",
       "\t10 & 1.0e-6 & 125 & 2 & 300 & 0.0001 & 64 & 2000 & 2 & $\\dots$ \\\\\n",
       "\t11 & 1.0e-6 & 125 & 2 & 300 & 0.0001 & 64 & 2000 & 2 & $\\dots$ \\\\\n",
       "\t12 & 1.0e-6 & 125 & 2 & 300 & 0.0001 & 64 & 2000 & 2 & $\\dots$ \\\\\n",
       "\t13 & 1.0e-6 & 125 & 2 & 300 & 0.0001 & 64 & 2000 & 2 & $\\dots$ \\\\\n",
       "\t14 & 1.0e-6 & 125 & 2 & 300 & 0.0001 & 64 & 2000 & 2 & $\\dots$ \\\\\n",
       "\t15 & 1.0e-6 & 125 & 2 & 300 & 0.0001 & 64 & 2000 & 2 & $\\dots$ \\\\\n",
       "\t16 & 1.0e-6 & 125 & 2 & 300 & 0.0001 & 64 & 2000 & 2 & $\\dots$ \\\\\n",
       "\t17 & 1.0e-6 & 125 & 2 & 300 & 0.0001 & 64 & 2000 & 2 & $\\dots$ \\\\\n",
       "\t18 & 1.0e-6 & 125 & 2 & 300 & 0.0001 & 64 & 2000 & 2 & $\\dots$ \\\\\n",
       "\t19 & 1.0e-6 & 125 & 2 & 300 & 0.0001 & 64 & 2000 & 2 & $\\dots$ \\\\\n",
       "\t20 & 1.0e-6 & 125 & 2 & 300 & 0.0001 & 64 & 2000 & 2 & $\\dots$ \\\\\n",
       "\t21 & 1.0e-6 & 125 & 2 & 300 & 0.0001 & 64 & 2000 & 2 & $\\dots$ \\\\\n",
       "\t22 & 1.0e-6 & 125 & 2 & 300 & 0.0001 & 64 & 2000 & 2 & $\\dots$ \\\\\n",
       "\t23 & 1.0e-6 & 125 & 2 & 300 & 0.0001 & 64 & 2000 & 2 & $\\dots$ \\\\\n",
       "\t24 & 1.0e-6 & 125 & 2 & 300 & 0.0001 & 64 & 2000 & 2 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m41×33 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m ae_lr   \u001b[0m\u001b[1m dim_redux \u001b[0m\u001b[1m ae_nb_hls \u001b[0m\u001b[1m nsamples \u001b[0m\u001b[1m cph_wd  \u001b[0m\u001b[1m cph_hl_size \u001b[0m\u001b[1m nepochs \u001b[0m\u001b[1m\u001b[0m ⋯\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Float64 \u001b[0m\u001b[90m Int64     \u001b[0m\u001b[90m Int64     \u001b[0m\u001b[90m Int64    \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Int64       \u001b[0m\u001b[90m Int64   \u001b[0m\u001b[90m\u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │  1.0e-6        125          2       300   0.0001           64     1000  ⋯\n",
       "   2 │  1.0e-6        125          2       300   0.0001           64     2000\n",
       "   3 │  1.0e-6        125          2       300   0.0001           64     2000\n",
       "   4 │  1.0e-6        125          2       300   0.0001           64     2000\n",
       "   5 │  1.0e-6        125          2       300   0.0001           64     2000  ⋯\n",
       "   6 │  1.0e-6        125          2       300   0.0001           64     2000\n",
       "   7 │  1.0e-6        125          2       300   0.0001           64     2000\n",
       "   8 │  1.0e-6        125          2       300   0.0001           64     2000\n",
       "  ⋮  │    ⋮         ⋮          ⋮         ⋮         ⋮          ⋮          ⋮     ⋱\n",
       "  35 │  1.0e-6        125          2       300   0.0001           64     2000  ⋯\n",
       "  36 │  1.0e-6        125          2       300   0.0001           64     2000\n",
       "  37 │  1.0e-6        125          2       300   0.0001           64     2000\n",
       "  38 │  1.0e-6        125          2       300   0.0001           64     2000\n",
       "  39 │  1.0e-6        125          2       300   0.0001           64     2000  ⋯\n",
       "  40 │  1.0e-6        125          2       300   0.0001           64     2000\n",
       "  41 │  1.0e-6        125          2       300   0.0001           64     2000\n",
       "\u001b[36m                                                  26 columns and 26 rows omitted\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function gather_params(basedir=\".\")\n",
    "    df = DataFrame()\n",
    "    for (root, dirs, files) in walkdir(basedir)\n",
    "        for file in files\n",
    "            if file == \"params.bson\"\n",
    "                # println(\"Loading $root/$file\")\n",
    "                d = BSON.load(\"$root/$file\")\n",
    "                push!(df, d, cols=:union)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return df\n",
    "end\n",
    "\n",
    "df = gather_params(\"RES/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "V1_2 = df[df.device .!= \"CuDevice(0)\",[\"device\",\"cph_tst_c_ind\", \"cph_train_c_ind\" ]]\n",
    "fig = Figure(resolution = (1024,512));\n",
    "ax = Axis(fig[1,1],\n",
    "    ylabel = \"Concordance index \", \n",
    "    xlabel = \"Version of CPHDNN\",\n",
    "    limits = (nothing, nothing, 0.5, 1),\n",
    "    xticks = ([1.,2.], unique(V1_2[:,\"device\"])))#(log2.(unique(V1[:, \"dim_redux\"])), [\"$x\" for x in unique(V1_2[:, \"dim_redux\"])] ));\n",
    "boxplot!(ax, [parse(Int, x[10]) for x in V1_2[:,\"device\"]], V1_2[:,\"cph_train_c_ind\"], label = \"train\")\n",
    "boxplot!(ax, [parse(Int, x[10]) for x in V1_2[:,\"device\"]], V1_2[:,\"cph_tst_c_ind\"], label = \"test\")\n",
    "#scatter!(ax, , V1[:,\"cph_tst_c_ind\"], label = \"test\")\n",
    "axislegend(ax,position =:rb)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6190208915071247"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean(V1_2[V1_2.device .== \"CuDevice(1)\",\"cph_tst_c_ind\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.4",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
