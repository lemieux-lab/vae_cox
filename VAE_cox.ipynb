{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISMB figures notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/vae_cox`\n"
     ]
    }
   ],
   "source": [
    "\n",
    "include(\"engines/init.jl\")\n",
    "include(\"engines/data_processing.jl\")\n",
    "include(\"engines/deep_learning.jl\")\n",
    "include(\"engines/cross_validation.jl\")\n",
    "outpath, session_id = set_dirs() ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BRCA = MLSurvDataset(\"Data/TCGA_BRCA_tpm_n1049_btypes_labels_surv.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLSurvDataset(Float32[0.008600163 0.0 … 0.0 0.0; 0.033423774 0.00432137 … 0.0 0.029383799; … ; 0.4828736 0.0 … 0.0 0.15836251; 0.045322984 0.017033324 … 0.0 0.20682588], [\"01H001\", \"02H003\", \"02H009\", \"02H017\", \"02H026\", \"02H033\", \"02H053\", \"02H066\", \"03H016\", \"03H022\"  …  \"13H186\", \"14H001\", \"14H007\", \"14H012\", \"14H015\", \"14H017\", \"14H019\", \"14H020\", \"14H023\", \"14H038\"], [\"TSPAN6\", \"TNMD\", \"DPM1\", \"SCYL3\", \"C1orf112\", \"FGR\", \"CFH\", \"FUCA2\", \"GCLC\", \"NFYA\"  …  \"AP003086.3\", \"AL109627.1\", \"AC084851.4\", \"AC024558.2\", \"AC108479.4\", \"AL512357.2\", \"AL138899.3\", \"AL669830.1\", \"AC091135.2\", \"AL357075.5\"], [\"lncRNA\", \"lncRNA\", \"protein_coding\", \"lncRNA\", \"protein_coding\", \"lncRNA\", \"protein_coding,retained_intron\", \"lncRNA\", \"protein_coding\", \"protein_coding\"  …  \"transcribed_processed_pseudogene\", \"lncRNA\", \"processed_pseudogene\", \"protein_coding\", \"unprocessed_pseudogene\", \"lncRNA\", \"protein_coding\", \"retained_intron\", \"unprocessed_pseudogene\", \"protein_coding\"], [\"Therapy-related myeloid neoplasms\", \"AML with minimal differentiation\", \"AML without maturation\", \"AML with minimal differentiation\", \"AML with myelodysplasia-related changes\", \"Acute monoblastic and monocytic leukaemia\", \"AML without maturation\", \"AML without maturation\", \"Acute monoblastic and monocytic leukaemia\", \"AML with myelodysplasia-related changes\"  …  \"Acute myelomonocytic leukaemia\", \"AML without maturation\", \"AML with maturation\", \"AML with minimal differentiation\", \"Acute myelomonocytic leukaemia\", \"AML without maturation\", \"AML with minimal differentiation\", \"AML without maturation\", \"AML with myelodysplasia-related changes\", \"AML with inv(3)(q21q26.2) or t(3;3)(q21;q26.2); RPN1-EVI1\"], [2170, 1396, 236, 284, 358, 101, 37, 135, 6033, 805  …  150, 2086, 75, 1467, 207, 213, 1983, 1952, 36, 255], [1, 1, 1, 1, 1, 1, 1, 1, 0, 1  …  1, 0, 1, 1, 1, 1, 0, 0, 1, 1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LAML = MLSurvDataset(\"Data/LGN_AML_tpm_n300_btypes_labels_surv.h5\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb genes : 14996\n",
      "nb patients : 300\n",
      "% uncensored : 0.7433333333333333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dict{String, Any} with 3 entries:\n",
       "  \"cph\"  => Chain(Dense(125 => 64, leakyrelu), Dense(64 => 64, leakyrelu), Dens…\n",
       "  \"venc\" => VariationalEncoder(Dense(14996 => 128, leakyrelu), Dense(128 => 125…\n",
       "  \"vdec\" => Chain(Dense(125 => 128, leakyrelu), Dense(128 => 14996))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "function data_prep(DATA;nfolds = 5, nepochs =1000, dim_redux= 125)\n",
    "    keep = [occursin(\"protein_coding\", bt) for bt in DATA.biotypes]\n",
    "    println(\"nb genes : $(sum(keep))\")\n",
    "    println(\"nb patients : $(size(DATA.samples)[1])\")\n",
    "    println(\"% uncensored : $(mean(DATA.surve .!= 0))\")\n",
    "    params_dict = Dict(\n",
    "            ## run infos \n",
    "            \"session_id\" => session_id, \"nfolds\" =>5,  \"modelid\" => \"$(bytes2hex(sha256(\"$(now())\"))[1:Int(floor(end/3))])\",\n",
    "            \"machine_id\"=>strip(read(`hostname`, String)), \"device\" => \"$(device())\", \"model_title\"=>\"AECPHDNN\",\n",
    "            ## data infos \n",
    "            \"dataset\" => \"BRCA_data(norm=true)\", \"nsamples\" => size(DATA.samples)[1],\n",
    "            \"nsamples_test\" => Int(round(size(DATA.samples)[1] / nfolds)), \"ngenes\" => size(DATA.genes[keep])[1],\n",
    "            \"nsamples_train\" => size(DATA.samples)[1] - Int(round(size(DATA.samples)[1] / nfolds)),\n",
    "            ## optim infos \n",
    "            \"nepochs\" => nepochs, \"ae_lr\" =>1e-6, \"cph_lr\" => 1e-5, \"ae_wd\" => 1e-6, \"cph_wd\" => 1e-4,\n",
    "            ## model infos\n",
    "            \"model_type\"=> \"vaecox\", \"dim_redux\" => dim_redux, \"ae_nb_hls\" => 2,\n",
    "            \"enc_nb_hl\" => 2, \"enc_hl_size\"=> 128,\n",
    "            \"venc_nb_hl\" => 2, \"venc_hl_size\"=> 128,  \"dec_nb_hl\" => 2 , \"dec_hl_size\"=> 128,\n",
    "            \"nb_clinf\" => 0, \"cph_nb_hl\" => 2, \"cph_hl_size\" => 64, \n",
    "            \"insize\" => size(DATA.genes[keep])[1],\n",
    "            ## metrics\n",
    "            \"model_cv_complete\" => false\n",
    "        )\n",
    "    # split train test\n",
    "    folds = split_train_test(Matrix(DATA.data[:,keep]), DATA.survt, DATA.surve, DATA.samples;nfolds =5)\n",
    "    fold = folds[1]\n",
    "    # format input data  \n",
    "    train_x, train_y_t, train_y_e, NE_frac_tr, test_x, test_y_t, test_y_e, NE_frac_tst = format_train_test(fold)\n",
    "\n",
    "    return train_x, train_y_t, train_y_e, NE_frac_tr, test_x, test_y_t, test_y_e, NE_frac_tst, params_dict\n",
    "end\n",
    "train_x, train_y_t, train_y_e, NE_frac_tr, test_x, test_y_t, test_y_e, NE_frac_tst, params_dict = data_prep(LAML)\n",
    "# create model \n",
    "model = build_vaecox(params_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "function build_vaecox(params_dict)\n",
    "    encoder = VariationalEncoder(params_dict[\"insize\"], params_dict[\"dim_redux\"], params_dict[\"venc_hl_size\"]) # chain \n",
    "    decoder = Decoder(params_dict[\"insize\"], params_dict[\"dim_redux\"], params_dict[\"venc_hl_size\"]) # chain \n",
    "    cph = gpu(Chain(Dense(params_dict[\"dim_redux\"], params_dict[\"cph_hl_size\"], leakyrelu), Dense(params_dict[\"cph_hl_size\"], params_dict[\"cph_hl_size\"],leakyrelu), Dense(params_dict[\"cph_hl_size\"], 1))) # chain \n",
    "    return Dict(\"venc\" => encoder,\n",
    "    \"vdec\" => decoder,\n",
    "    \"cph\" => cph )\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE_COX_loss (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function VAE_COX_loss(VENC, CPH, X, Y_e, NE_frac;device = gpu)\n",
    "    mu, log_sigma = VENC(X)\n",
    "    #z = mu + device(randn(Float32, size(log_sigma))) .* exp.(log_sigma)\n",
    "    outs = vec(CPH(mu))\n",
    "    hazard_ratios = exp.(outs)\n",
    "    log_risk = log.(cumsum(hazard_ratios))\n",
    "    uncensored_likelihood = outs .- log_risk\n",
    "    censored_likelihood = uncensored_likelihood .* Y_e'\n",
    "    #neg_likelihood = - sum(censored_likelihood) / sum(e .== 1)\n",
    "    neg_likelihood = - sum(censored_likelihood) * NE_frac\n",
    "    return neg_likelihood\n",
    "end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "format_train_test (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function format_train_test(fold; device = gpu)\n",
    "    nsamples = size(fold[\"train_x\"])[1]\n",
    "    ordering = collect(1:nsamples)#sortperm(-fold[\"Y_t_train\"])\n",
    "    train_x = device(Matrix(fold[\"train_x\"][ordering,:]'));\n",
    "    train_y_t = device(Matrix(fold[\"Y_t_train\"][ordering,:]'));\n",
    "    train_y_e = device(Matrix(fold[\"Y_e_train\"][ordering,:]'));\n",
    "    NE_frac_tr = sum(train_y_e .== 1) != 0 ? 1 / sum(train_y_e .== 1) : 0\n",
    "\n",
    "    nsamples = size(fold[\"test_x\"])[1]\n",
    "    ordering = collect(1:nsamples)#sortperm(-fold[\"Y_t_test\"])\n",
    "    test_x = device(Matrix(fold[\"test_x\"][ordering,:]'));\n",
    "    test_y_t = device(Matrix(fold[\"Y_t_test\"][ordering,:]'));\n",
    "    test_y_e = device(Matrix(fold[\"Y_e_test\"][ordering,:]'));\n",
    "    NE_frac_tst = sum(test_y_e .== 1) != 0 ? 1 / sum(test_y_e .== 1) : 0\n",
    "    return train_x, train_y_t, train_y_e, NE_frac_tr, test_x, test_y_t, test_y_e, NE_frac_tst\n",
    "end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cox_nll_vec (generic function with 6 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function cox_nll_vec(mdl::Chain, X_, Y_e_, NE_frac)\n",
    "    outs = vec(mdl(X_))\n",
    "    #outs = vec(mdl.cphdnn(mdl.encoder(X_)))\n",
    "    hazard_ratios = exp.(outs)\n",
    "    log_risk = log.(cumsum(hazard_ratios))\n",
    "    uncensored_likelihood = outs .- log_risk\n",
    "    censored_likelihood = uncensored_likelihood .* Y_e_'\n",
    "    #neg_likelihood = - sum(censored_likelihood) / sum(e .== 1)\n",
    "    neg_likelihood = - sum(censored_likelihood) * NE_frac\n",
    "    return neg_likelihood\n",
    "end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb genes : 14996\n",
      "nb patients : 300\n",
      "% uncensored : 0.7433333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 TRAIN 5.117351373931716 cind: 0.507 \t TEST cind: 0.518 [824, 768, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 TRAIN 2.1551450381452866 cind: 0.42 \t TEST cind: 0.41 [652, 940, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 TRAIN NaN cind: NaN \t TEST cind: NaN [0, 0, -60]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 TRAIN NaN cind: NaN \t TEST cind: NaN [0, 0, -60]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 TRAIN NaN cind: NaN \t TEST cind: NaN [0, 0, -60]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 TRAIN NaN cind: NaN \t TEST cind: NaN [0, 0, -60]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 TRAIN NaN cind: NaN \t TEST cind: NaN [0, 0, -60]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700 TRAIN NaN cind: NaN \t TEST cind: NaN [0, 0, -60]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800 TRAIN NaN cind: NaN \t TEST cind: NaN [0, 0, -60]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900 TRAIN NaN cind: NaN \t TEST cind: NaN [0, 0, -60]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 TRAIN NaN cind: NaN \t TEST cind: NaN [0, 0, -60]\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y_t, train_y_e, NE_frac_tr, test_x, test_y_t, test_y_e, NE_frac_tst, params_dict = data_prep(LAML)\n",
    "# create model \n",
    "#model = build_vaecox(params_dict)\n",
    "cphdnn = gpu(Chain(Dense(size(train_x)[1], 3040, leakyrelu), Dense(3040, 616, leakyrelu), Dense(616,128, leakyrelu), Dense(128,64, leakyrelu),Dense(64, 1, bias = false)))\n",
    "opt = Flux.ADAM(1e-4)\n",
    "wd = params_dict[\"cph_wd\"]\n",
    "for i in 1:1000\n",
    "    ps1 = Flux.params(cphdnn)\n",
    "    gs1 = gradient(ps1) do \n",
    "        cox_nll_vec(cphdnn, train_x, train_y_e, NE_frac_tr) + l2_penalty(cphdnn) * wd\n",
    "        #VAE_COX_loss(model[\"venc\"], model[\"cph\"], train_x, train_y_e, NE_frac_tr) + l2_penalty(model[\"venc\"]) * wd + l2_penalty(model[\"cph\"]) * wd \n",
    "    end \n",
    "    cphloss = cox_nll_vec(cphdnn, train_x, train_y_e, NE_frac_tr) + l2_penalty(cphdnn) * wd\n",
    "    #cphloss = round(VAE_COX_loss(model[\"venc\"], model[\"cph\"], train_x, train_y_e, NE_frac_tr) + l2_penalty(model[\"venc\"]) * wd + l2_penalty(model[\"cph\"]) * wd , digits = 3)\n",
    "    #OUTS_tr = model[\"cph\"](model[\"venc\"](train_x)[1])\n",
    "    #OUTS_tst =  model[\"cph\"](model[\"venc\"](test_x)[1])\n",
    "    OUTS_tr = cphdnn(train_x)\n",
    "    OUTS_tst = cphdnn(test_x)\n",
    "    cind_tr, cdnt_tr, ddnt_tr, tied_tr  = concordance_index(train_y_t, train_y_e, OUTS_tr)\n",
    "    cind_test,cdnt_tst, ddnt_tst, tied_tst = concordance_index(test_y_t, test_y_e,OUTS_tst)\n",
    "    \n",
    "    if i%100==0 || i == 1\n",
    "    println(\"$i TRAIN $cphloss cind: $(round(cind_tr, digits = 3)) \\t TEST cind: $(round(cind_test, digits = 3)) [$(Int(cdnt_tst)), $(Int(ddnt_tst)), $(Int(tied_tst))]\")\n",
    "    end \n",
    "    Flux.update!(opt,ps1, gs1)\n",
    "end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cox_nll_vec (generic function with 6 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cphdnn = gpu(Chain(Dense(size(DATA.data[:,keep])[2], 64, leakyrelu), Dense(64, 64,leakyrelu),Dense(64, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y_t, train_y_e, NE_frac_tr, test_x, test_y_t, test_y_e, NE_frac_tst = format_train_test(fold)\n",
    "cphdnn(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function validate_vaecox(DATA, params_dict;device = gpu)\n",
    "    nfolds, nepochs, dim_redux = 5, 1000, 125\n",
    "    keep = [occursin(\"protein_coding\", bt) for bt in DATA.biotypes]\n",
    "    # split train test\n",
    "    folds = split_train_test(Matrix(DATA.data[:,keep]), DATA.survt, DATA.surve, DATA.samples;nfolds =5)\n",
    "    fold = folds[1]\n",
    "\n",
    "    venc = VariationalEncoder(size(DATA.data[:,keep])[2], 125, 600)\n",
    "    vdec = Decoder(size(DATA.data[:,keep])[2], 125, 600)\n",
    "    VAE_opt = Flux.ADAM(1e-4)\n",
    "\n",
    "    cphdnn = device(Chain(Dense(size(DATA.data[:,keep])[2], 125, leakyrelu), Dense(125, 100,leakyrelu),Dense(100, 1)))\n",
    "    cphdnn_opt = Flux.ADAM(1e-5)\n",
    "\n",
    "    train_x, train_y_t, train_y_e, NE_frac_tr, test_x, test_y_t, test_y_e, NE_frac_tst = format_train_test(fold)\n",
    "    for i in 1:nepochs\n",
    "        ps1 = Flux.params(venc, vdec)\n",
    "        gs1 = gradient(ps1) do\n",
    "            VAE_lossf(venc, vdec, train_x)\n",
    "        end \n",
    "        VAE_loss = VAE_lossf(venc, vdec, train_x)\n",
    "        VAE_cor = round(my_cor(vec(train_x), vec(MyReconstruct(venc, vdec, train_x)[end])),digits = 3)\n",
    "        VAE_test = round(my_cor(vec(test_x), vec(MyReconstruct(venc, vdec, test_x)[end])),digits = 3)\n",
    "\n",
    "        ps2 = Flux.params(venc, cphdnn)\n",
    "        gs2 = gradient(ps2) do \n",
    "            cox_nll_vec(cphdnn, train_x, train_y_e, NE_frac_tr)\n",
    "            #VAE_COX_loss(venc, cphdnn, train_x, train_y_e, NE_frac_tr)\n",
    "        end \n",
    "        CPH_loss = round(cox_nll_vec(cphdnn, train_x, train_y_e, NE_frac_tr), digits = 3) #round(VAE_COX_loss(venc, cphdnn, train_x, train_y_e, NE_frac_tr), digits = 3)\n",
    "        #mu, log_sigma = venc(train_x)\n",
    "        #z = mu + device(randn(Float32, size(log_sigma))) .* exp.(log_sigma)\n",
    "        #OUTS_tr = vec(cphdnn(z))\n",
    "        OUTS_tr = cphdnn(train_x)\n",
    "        OUTS_tst =  cphdnn(test_x)\n",
    "        cind_tr, cdnt_tr, ddnt_tr, tied_tr  = concordance_index(train_y_t, train_y_e, OUTS_tr)\n",
    "        cind_test,cdnt_tst, ddnt_tst, tied_tst = concordance_index(test_y_t, test_y_e,OUTS_tst)\n",
    "        #Flux.update!(VAE_opt, ps1, gs1)\n",
    "        Flux.update!(cphdnn_opt, ps2, gs2)\n",
    "        if i % 100 == 0 || i == 1\n",
    "            println(\"$i TRAIN - VAE-loss-avg: $VAE_loss\\tVAE-cor: $VAE_cor CPH-loss: $CPH_loss CPH-cind: $(round(cind_tr,digits=3))\")\n",
    "            println(\"$i TEST - VAE-loss-avg: $VAE_test \\tVAE-cor: CPH-loss: CPH-cind: $(round(cind_test,digits=3)) [$(Int(cdnt_tst)), $(Int(ddnt_tst)), $(Int(tied_tst))]\")\n",
    "\n",
    "        end\n",
    "    end\n",
    "    return cphdnn\n",
    "end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdnn = validate_vaecox(DATA, params_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdnn(DATA.data[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb genes : 14996\n",
      "nb patients : 300\n",
      "% uncensored : 0.7433333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1\t TRAIN AE-loss 1.0 \t AE-cor: 0.01\t cph-loss-avg: 0.018436 \t cph-cind: 0.498\n",
      "\t\tTEST AE-loss 0.99 \t AE-cor: 0.013\t cph-loss-avg: 0.051483 \t cph-cind: 0.479 [787, 855, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 100\t TRAIN AE-loss 0.786 \t AE-cor: 0.247\t cph-loss-avg: 0.017247 \t cph-cind: 0.648\n",
      "\t\tTEST AE-loss 0.78 \t AE-cor: 0.248\t cph-loss-avg: 0.050717 \t cph-cind: 0.612 [1005, 637, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 200\t TRAIN AE-loss 0.52 \t AE-cor: 0.516\t cph-loss-avg: 0.017099 \t cph-cind: 0.651\n",
      "\t\tTEST AE-loss 0.52 \t AE-cor: 0.514\t cph-loss-avg: 0.050767 \t cph-cind: 0.611 [1003, 639, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 300\t TRAIN AE-loss 0.297 \t AE-cor: 0.73\t cph-loss-avg: 0.017073 \t cph-cind: 0.652\n",
      "\t\tTEST AE-loss 0.302 \t AE-cor: 0.724\t cph-loss-avg: 0.050817 \t cph-cind: 0.622 [1022, 620, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 400\t TRAIN AE-loss 0.161 \t AE-cor: 0.859\t cph-loss-avg: 0.017062 \t cph-cind: 0.65\n",
      "\t\tTEST AE-loss 0.169 \t AE-cor: 0.851\t cph-loss-avg: 0.0508 \t cph-cind: 0.631 [1036, 606, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 500\t TRAIN AE-loss 0.093 \t AE-cor: 0.923\t cph-loss-avg: 0.017053 \t cph-cind: 0.647\n",
      "\t\tTEST AE-loss 0.103 \t AE-cor: 0.914\t cph-loss-avg: 0.050917 \t cph-cind: 0.624 [1024, 618, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 600\t TRAIN AE-loss 0.065 \t AE-cor: 0.949\t cph-loss-avg: 0.017042 \t cph-cind: 0.655\n",
      "\t\tTEST AE-loss 0.075 \t AE-cor: 0.94\t cph-loss-avg: 0.050917 \t cph-cind: 0.627 [1029, 613, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 700\t TRAIN AE-loss 0.056 \t AE-cor: 0.957\t cph-loss-avg: 0.017045 \t cph-cind: 0.656\n",
      "\t\tTEST AE-loss 0.066 \t AE-cor: 0.948\t cph-loss-avg: 0.051083 \t cph-cind: 0.629 [1033, 609, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 800\t TRAIN AE-loss 0.054 \t AE-cor: 0.96\t cph-loss-avg: 0.017039 \t cph-cind: 0.657\n",
      "\t\tTEST AE-loss 0.064 \t AE-cor: 0.951\t cph-loss-avg: 0.05095 \t cph-cind: 0.63 [1035, 607, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 900\t TRAIN AE-loss 0.053 \t AE-cor: 0.961\t cph-loss-avg: 0.017038 \t cph-cind: 0.657\n",
      "\t\tTEST AE-loss 0.063 \t AE-cor: 0.951\t cph-loss-avg: 0.051 \t cph-cind: 0.629 [1032, 610, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1000\t TRAIN AE-loss 0.052 \t AE-cor: 0.961\t cph-loss-avg: 0.017038 \t cph-cind: 0.658\n",
      "\t\tTEST AE-loss 0.062 \t AE-cor: 0.951\t cph-loss-avg: 0.051 \t cph-cind: 0.629 [1033, 609, 0]\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y_t, train_y_e, NE_frac_tr, test_x, test_y_t, test_y_e, NE_frac_tst, params_dict = data_prep(LAML)\n",
    "# create model \n",
    "model = build_aecox(params_dict)\n",
    "for iter in 1:params_dict[\"nepochs\"]\n",
    "    ps1 = Flux.params(model[\"cph\"].model, model[\"enc\"])\n",
    "    gs1 = gradient(ps1) do\n",
    "        model[\"cph\"].lossf(model[\"cph\"],model[\"enc\"], train_x, train_y_e, NE_frac_tr, params_dict[\"cph_wd\"])\n",
    "    end \n",
    "    ## gradient Auto-Encoder \n",
    "    ps2 = Flux.params(model[\"ae\"].net)\n",
    "    gs2 = gradient(ps2) do\n",
    "        model[\"ae\"].lossf(model[\"ae\"], train_x, train_x, weight_decay = params_dict[\"ae_wd\"])\n",
    "    end\n",
    "    Flux.update!(model[\"cph\"].opt, ps1, gs1)\n",
    "    #Flux.update!(model[\"ae\"].opt, ps2, gs2)\n",
    "\n",
    "    ######\n",
    "    OUTS_tr = vec(model[\"cph\"].model(model[\"enc\"](train_x)))\n",
    "    ae_loss = model[\"ae\"].lossf(model[\"ae\"], train_x, train_x, weight_decay = params_dict[\"ae_wd\"])\n",
    "    ae_cor =  round(my_cor(vec(train_x), vec(model[\"ae\"].net(train_x))),digits = 3)\n",
    "    cph_loss = model[\"cph\"].lossf(model[\"cph\"],model[\"enc\"](train_x), train_y_e, NE_frac_tr, params_dict[\"cph_wd\"])\n",
    "    ae_loss_test = round(model[\"ae\"].lossf(model[\"ae\"], test_x, test_x, weight_decay = params_dict[\"ae_wd\"]), digits = 3)\n",
    "    ae_cor_test = round(my_cor(vec(test_x), vec(model[\"ae\"].net(test_x))), digits= 3)\n",
    "    cph_loss_test = round(model[\"cph\"].lossf(model[\"cph\"],model[\"enc\"](test_x), test_y_e, NE_frac_tst, params_dict[\"cph_wd\"]), digits= 3)\n",
    "                    \n",
    "    OUTS_tst =  vec(model[\"cph\"].model(model[\"enc\"](test_x)))\n",
    "            \n",
    "    cind_tr, cdnt_tr, ddnt_tr, tied_tr  = concordance_index(train_y_t, train_y_e, OUTS_tr)\n",
    "    cind_test,cdnt_tst, ddnt_tst, tied_tst = concordance_index(test_y_t, test_y_e,OUTS_tst)\n",
    "    if iter % 100 == 0  || iter == 1     \n",
    "        println(\"FOLD $iter\\t TRAIN AE-loss $(round(ae_loss,digits =3)) \\t AE-cor: $(round(ae_cor, digits = 3))\\t cph-loss-avg: $(round(cph_loss / params_dict[\"nsamples_train\"],digits =6)) \\t cph-cind: $(round(cind_tr,digits =3))\")\n",
    "        println(\"\\t\\tTEST AE-loss $(round(ae_loss_test,digits =3)) \\t AE-cor: $(round(ae_cor_test, digits = 3))\\t cph-loss-avg: $(round(cph_loss_test / params_dict[\"nsamples_test\"],digits =6)) \\t cph-cind: $(round(cind_test,digits =3)) [$(Int(cdnt_tst)), $(Int(ddnt_tst)), $(Int(tied_tst))]\")\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Dense(125 => 64, leakyrelu),          \u001b[90m# 8_064 parameters\u001b[39m\n",
       "  Dense(64 => 1, σ; bias=false),        \u001b[90m# 64 parameters\u001b[39m\n",
       ") \u001b[90m                  # Total: 3 arrays, \u001b[39m8_128 parameters, 464 bytes."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model[\"cph\"].model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dict[\"cph_tst_c_ind\"] = concordance_index(yt_test, ye_test, -1 .* cph_outs_test)[1]\n",
    "params_dict[\"cph_train_c_ind\"] = concordance_index(yt_train, ye_train, -1 .* cph_outs_train)[1]\n",
    "params_dict[\"ae_tst_corr\"] = my_cor(ae_outs_test, x_test)\n",
    "params_dict[\"ae_train_corr\"] = my_cor(ae_outs_train, x_train)\n",
    "\n",
    "params_dict[\"model_cv_complete\"] = true\n",
    "bson(\"RES/$model_params_path/params.bson\",params_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.4",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
