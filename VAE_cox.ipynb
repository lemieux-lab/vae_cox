{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISMB figures notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/vae_cox`\n"
     ]
    }
   ],
   "source": [
    "\n",
    "include(\"engines/init.jl\")\n",
    "include(\"engines/data_processing.jl\")\n",
    "include(\"engines/deep_learning.jl\")\n",
    "include(\"engines/cross_validation.jl\")\n",
    "outpath, session_id = set_dirs() ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BRCA = MLSurvDataset(\"Data/TCGA_BRCA_tpm_n1049_btypes_labels_surv.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLSurvDataset(Float32[0.008600163 0.0 … 0.0 0.0; 0.033423774 0.00432137 … 0.0 0.029383799; … ; 0.4828736 0.0 … 0.0 0.15836251; 0.045322984 0.017033324 … 0.0 0.20682588], [\"01H001\", \"02H003\", \"02H009\", \"02H017\", \"02H026\", \"02H033\", \"02H053\", \"02H066\", \"03H016\", \"03H022\"  …  \"13H186\", \"14H001\", \"14H007\", \"14H012\", \"14H015\", \"14H017\", \"14H019\", \"14H020\", \"14H023\", \"14H038\"], [\"TSPAN6\", \"TNMD\", \"DPM1\", \"SCYL3\", \"C1orf112\", \"FGR\", \"CFH\", \"FUCA2\", \"GCLC\", \"NFYA\"  …  \"AP003086.3\", \"AL109627.1\", \"AC084851.4\", \"AC024558.2\", \"AC108479.4\", \"AL512357.2\", \"AL138899.3\", \"AL669830.1\", \"AC091135.2\", \"AL357075.5\"], [\"lncRNA\", \"lncRNA\", \"protein_coding\", \"lncRNA\", \"protein_coding\", \"lncRNA\", \"protein_coding,retained_intron\", \"lncRNA\", \"protein_coding\", \"protein_coding\"  …  \"transcribed_processed_pseudogene\", \"lncRNA\", \"processed_pseudogene\", \"protein_coding\", \"unprocessed_pseudogene\", \"lncRNA\", \"protein_coding\", \"retained_intron\", \"unprocessed_pseudogene\", \"protein_coding\"], [\"Therapy-related myeloid neoplasms\", \"AML with minimal differentiation\", \"AML without maturation\", \"AML with minimal differentiation\", \"AML with myelodysplasia-related changes\", \"Acute monoblastic and monocytic leukaemia\", \"AML without maturation\", \"AML without maturation\", \"Acute monoblastic and monocytic leukaemia\", \"AML with myelodysplasia-related changes\"  …  \"Acute myelomonocytic leukaemia\", \"AML without maturation\", \"AML with maturation\", \"AML with minimal differentiation\", \"Acute myelomonocytic leukaemia\", \"AML without maturation\", \"AML with minimal differentiation\", \"AML without maturation\", \"AML with myelodysplasia-related changes\", \"AML with inv(3)(q21q26.2) or t(3;3)(q21;q26.2); RPN1-EVI1\"], [2170, 1396, 236, 284, 358, 101, 37, 135, 6033, 805  …  150, 2086, 75, 1467, 207, 213, 1983, 1952, 36, 255], [1, 1, 1, 1, 1, 1, 1, 1, 0, 1  …  1, 0, 1, 1, 1, 1, 0, 0, 1, 1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LAML = MLSurvDataset(\"Data/LGN_AML_tpm_n300_btypes_labels_surv.h5\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BRCA_pcoding = BRCA.biotypes .== \"protein_coding\"\n",
    "println(sum(BRCA_pcoding))\n",
    "println(size(BRCA.samples)[1])\n",
    "println(mean(BRCA.surve .!= 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcoding = [occursin(\"protein_coding\", bt) for bt in LAML.biotypes]\n",
    "println(size(LAML.genes[pcoding])[1])\n",
    "println(mean(LAML.surve .!= 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing VAE-Cox\n",
    "# set hyper parameters \n",
    "DATA = BRCA\n",
    "keep = BRCA_pcoding\n",
    "# split train test\n",
    "folds = split_train_test(Matrix(DATA.data[:,keep]), DATA.survt, DATA.surve, DATA.samples;nfolds =5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device!()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14996\n",
      "300\n",
      "0.7433333333333333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dict{String, Any} with 3 entries:\n",
       "  \"ae\"  => AE_model(Chain(Dense(14996 => 3040, leakyrelu), Dense(3040 => 616, l…\n",
       "  \"cph\" => dnn(Chain(Dense(125 => 64, leakyrelu), Dense(64 => 1, σ; bias=false)…\n",
       "  \"enc\" => Chain(Dense(14996 => 3040, leakyrelu), Dense(3040 => 616, leakyrelu)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# testing VAE-Cox\n",
    "# set hyper parameters \n",
    "DATA,nfolds, nepochs, dim_redux = LAML, 5, 1000, 125\n",
    "keep = [occursin(\"protein_coding\", bt) for bt in DATA.biotypes]\n",
    "println(sum(keep))\n",
    "println(size(DATA.samples)[1])\n",
    "println(mean(DATA.surve .!= 0))\n",
    "params_dict = Dict(\n",
    "        ## run infos \n",
    "        \"session_id\" => session_id, \"nfolds\" =>5,  \"modelid\" => \"$(bytes2hex(sha256(\"$(now())\"))[1:Int(floor(end/3))])\",\n",
    "        \"machine_id\"=>strip(read(`hostname`, String)), \"device\" => \"$(device())\", \"model_title\"=>\"AECPHDNN\",\n",
    "        ## data infos \n",
    "        \"dataset\" => \"BRCA_data(norm=true)\", \"nsamples\" => size(DATA.samples)[1],\n",
    "        \"nsamples_test\" => Int(round(size(DATA.samples)[1] / nfolds)), \"ngenes\" => size(DATA.genes[keep])[1],\n",
    "        \"nsamples_train\" => size(DATA.samples)[1] - Int(round(size(DATA.samples)[1] / nfolds)),\n",
    "        ## optim infos \n",
    "        \"nepochs\" => nepochs, \"ae_lr\" =>1e-6, \"cph_lr\" => 1e-6, \"ae_wd\" => 1e-6, \"cph_wd\" => 1e-4,\n",
    "        ## model infos\n",
    "        \"model_type\"=> \"aecphdnn\", \"dim_redux\" => dim_redux, \"ae_nb_hls\" => 2, \"ae_hl_size\"=> 128,\n",
    "        \"enc_nb_hl\" => 2, \"enc_hl_size\"=> 128,  \"dec_nb_hl\" => 2 , \"dec_hl_size\"=> 128,\n",
    "        \"nb_clinf\" => 0, \"cph_nb_hl\" => 2, \"cph_hl_size\" => 64, \n",
    "        \"insize\" => size(DATA.genes[keep])[1],\n",
    "        ## metrics\n",
    "        \"model_cv_complete\" => false\n",
    "    )\n",
    "# split train test\n",
    "folds = split_train_test(Matrix(DATA.data[:,keep]), DATA.survt, DATA.surve, DATA.samples;nfolds =5)\n",
    "fold = folds[1]\n",
    "# format input data  \n",
    "train_x, train_y_t, train_y_e, NE_frac_tr, test_x, test_y_t, test_y_e, NE_frac_tst = format_train_test(fold)\n",
    "# create model \n",
    "model = build_vaecox(params_dict)\n",
    "# train model \n",
    "## gradient CPH            \n",
    "\n",
    "# report learning curves\n",
    "# test model\n",
    "# report c-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE_COX_loss (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function VAE_COX_loss(VENC, CPH, X, Y_e, NE_frac;device = gpu)\n",
    "    mu, log_sigma = VENC(X)\n",
    "    z = mu + device(randn(Float32, size(log_sigma))) .* exp.(log_sigma)\n",
    "    outs = vec(CPH(z))\n",
    "    hazard_ratios = exp.(outs)\n",
    "    log_risk = log.(cumsum(hazard_ratios))\n",
    "    uncensored_likelihood = outs .- log_risk\n",
    "    censored_likelihood = uncensored_likelihood .* Y_e'\n",
    "    #neg_likelihood = - sum(censored_likelihood) / sum(e .== 1)\n",
    "    neg_likelihood = - sum(censored_likelihood) * NE_frac\n",
    "    return neg_likelihood\n",
    "end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cox_nll_vec (generic function with 6 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function cox_nll_vec(mdl::Chain, X_, Y_e_, NE_frac)\n",
    "    outs = vec(mdl(X_))\n",
    "    #outs = vec(mdl.cphdnn(mdl.encoder(X_)))\n",
    "    hazard_ratios = exp.(outs)\n",
    "    log_risk = log.(cumsum(hazard_ratios))\n",
    "    uncensored_likelihood = outs .- log_risk\n",
    "    censored_likelihood = uncensored_likelihood .* Y_e_'\n",
    "    #neg_likelihood = - sum(censored_likelihood) / sum(e .== 1)\n",
    "    neg_likelihood = - sum(censored_likelihood) * NE_frac\n",
    "    return neg_likelihood\n",
    "end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Dense(14996 => 125, leakyrelu),       \u001b[90m# 1_874_625 parameters\u001b[39m\n",
       "  Dense(125 => 100, leakyrelu),         \u001b[90m# 12_600 parameters\u001b[39m\n",
       "  Dense(100 => 1),                      \u001b[90m# 101 parameters\u001b[39m\n",
       ") \u001b[90m                  # Total: 6 arrays, \u001b[39m1_887_326 parameters, 856 bytes."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cphdnn = gpu(Chain(Dense(size(DATA.data[:,keep])[2], 125, leakyrelu), Dense(125, 100,leakyrelu),Dense(100, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×240 CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}:\n",
       " 0.804183  0.6966  0.642762  0.544045  …  0.874874  1.00074  0.824527"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_x, train_y_t, train_y_e, NE_frac_tr, test_x, test_y_t, test_y_e, NE_frac_tst = format_train_test(fold)\n",
    "cphdnn(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "validate_vaecox (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function validate_vaecox(DATA, params_dict;device = gpu)\n",
    "    nfolds, nepochs, dim_redux = 5, 1000, 125\n",
    "    keep = [occursin(\"protein_coding\", bt) for bt in DATA.biotypes]\n",
    "    # split train test\n",
    "    folds = split_train_test(Matrix(DATA.data[:,keep]), DATA.survt, DATA.surve, DATA.samples;nfolds =5)\n",
    "    fold = folds[1]\n",
    "\n",
    "    venc = VariationalEncoder(size(DATA.data[:,keep])[2], 125, 600)\n",
    "    vdec = Decoder(size(DATA.data[:,keep])[2], 125, 600)\n",
    "    VAE_opt = Flux.ADAM(1e-4)\n",
    "\n",
    "    cphdnn = device(Chain(Dense(size(DATA.data[:,keep])[2], 125, leakyrelu), Dense(125, 100,leakyrelu),Dense(100, 1)))\n",
    "    cphdnn_opt = Flux.ADAM(1e-5)\n",
    "\n",
    "    train_x, train_y_t, train_y_e, NE_frac_tr, test_x, test_y_t, test_y_e, NE_frac_tst = format_train_test(fold)\n",
    "    for i in 1:nepochs\n",
    "        ps1 = Flux.params(venc, vdec)\n",
    "        gs1 = gradient(ps1) do\n",
    "            VAE_lossf(venc, vdec, train_x)\n",
    "        end \n",
    "        VAE_loss = VAE_lossf(venc, vdec, train_x)\n",
    "        VAE_cor = round(my_cor(vec(train_x), vec(MyReconstruct(venc, vdec, train_x)[end])),digits = 3)\n",
    "        VAE_test = round(my_cor(vec(test_x), vec(MyReconstruct(venc, vdec, test_x)[end])),digits = 3)\n",
    "\n",
    "        ps2 = Flux.params(venc, cphdnn)\n",
    "        gs2 = gradient(ps2) do \n",
    "            cox_nll_vec(cphdnn, train_x, train_y_e, NE_frac_tr)\n",
    "            #VAE_COX_loss(venc, cphdnn, train_x, train_y_e, NE_frac_tr)\n",
    "        end \n",
    "        CPH_loss = round(cox_nll_vec(cphdnn, train_x, train_y_e, NE_frac_tr), digits = 3) #round(VAE_COX_loss(venc, cphdnn, train_x, train_y_e, NE_frac_tr), digits = 3)\n",
    "        #mu, log_sigma = venc(train_x)\n",
    "        #z = mu + device(randn(Float32, size(log_sigma))) .* exp.(log_sigma)\n",
    "        #OUTS_tr = vec(cphdnn(z))\n",
    "        OUTS_tr = cphdnn(train_x)\n",
    "        cind_tr, cdnt_tr, ddnt_tr, tied_tr  = concordance_index(train_y_t, train_y_e, OUTS_tr)\n",
    "\n",
    "        #Flux.update!(VAE_opt, ps1, gs1)\n",
    "        Flux.update!(cphdnn_opt, ps2, gs2)\n",
    "        if i % 100 == 0 || i == 1\n",
    "            println(\"$i TRAIN - VAE-loss-avg: $VAE_loss\\tVAE-cor: $VAE_cor CPH-loss: $CPH_loss CPH-cind: $(round(cind_tr,digits=3))\\tTEST - VAE-cor: $VAE_test\")\n",
    "        end\n",
    "    end\n",
    "end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 TRAIN - VAE-loss-avg: 19349.998\tVAE-cor: 0.007 CPH-loss: 5.052 CPH-cind: 0.582\tTEST - VAE-cor: 0.009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 TRAIN - VAE-loss-avg: 19451.33\tVAE-cor: 0.007 CPH-loss: 4.388 CPH-cind: 0.189\tTEST - VAE-cor: 0.007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 TRAIN - VAE-loss-avg: 19240.607\tVAE-cor: 0.007 CPH-loss: 4.023 CPH-cind: 0.117\tTEST - VAE-cor: 0.008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 TRAIN - VAE-loss-avg: 19241.342\tVAE-cor: 0.008 CPH-loss: 3.7 CPH-cind: 0.076\tTEST - VAE-cor: 0.006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 TRAIN - VAE-loss-avg: 19323.492\tVAE-cor: 0.008 CPH-loss: 3.369 CPH-cind: 0.046\tTEST - VAE-cor: 0.008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 TRAIN - VAE-loss-avg: 19401.654\tVAE-cor: 0.008 CPH-loss: 3.12 CPH-cind: 0.029\tTEST - VAE-cor: 0.007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 TRAIN - VAE-loss-avg: 19184.316\tVAE-cor: 0.008 CPH-loss: 2.907 CPH-cind: 0.019\tTEST - VAE-cor: 0.006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700 TRAIN - VAE-loss-avg: 19168.014\tVAE-cor: 0.008 CPH-loss: 2.711 CPH-cind: 0.012\tTEST - VAE-cor: 0.008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800 TRAIN - VAE-loss-avg: 19352.445\tVAE-cor: 0.007 CPH-loss: 2.533 CPH-cind: 0.007\tTEST - VAE-cor: 0.009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900 TRAIN - VAE-loss-avg: 19244.887\tVAE-cor: 0.008 CPH-loss: 2.371 CPH-cind: 0.004\tTEST - VAE-cor: 0.006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 TRAIN - VAE-loss-avg: 19375.945\tVAE-cor: 0.007 CPH-loss: 2.225 CPH-cind: 0.002\tTEST - VAE-cor: 0.007\n"
     ]
    }
   ],
   "source": [
    "validate_vaecox(DATA, params_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1 1\t TRAIN AE-loss 0.063 \t AE-cor: 0.954\t cph-loss-avg: 0.018939 \t cph-cind: 0.844\n",
      "\t\tTEST AE-loss 0.073 \t AE-cor: 0.946\t cph-loss-avg: 0.056767 \t cph-cind: 0.709 [1138, 466, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1 100\t TRAIN AE-loss 0.054 \t AE-cor: 0.961\t cph-loss-avg: 0.020494 \t cph-cind: 0.831\n",
      "\t\tTEST AE-loss 0.063 \t AE-cor: 0.952\t cph-loss-avg: 0.058883 \t cph-cind: 0.696 [1117, 487, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1 200\t TRAIN AE-loss 0.054 \t AE-cor: 0.961\t cph-loss-avg: 0.020517 \t cph-cind: 0.828\n",
      "\t\tTEST AE-loss 0.063 \t AE-cor: 0.953\t cph-loss-avg: 0.058967 \t cph-cind: 0.693 [1112, 492, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1 300\t TRAIN AE-loss 0.053 \t AE-cor: 0.961\t cph-loss-avg: 0.020525 \t cph-cind: 0.827\n",
      "\t\tTEST AE-loss 0.063 \t AE-cor: 0.953\t cph-loss-avg: 0.059 \t cph-cind: 0.691 [1109, 495, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1 400\t TRAIN AE-loss 0.053 \t AE-cor: 0.961\t cph-loss-avg: 0.020529 \t cph-cind: 0.826\n",
      "\t\tTEST AE-loss 0.063 \t AE-cor: 0.953\t cph-loss-avg: 0.059017 \t cph-cind: 0.69 [1106, 498, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1 500\t TRAIN AE-loss 0.053 \t AE-cor: 0.961\t cph-loss-avg: 0.020532 \t cph-cind: 0.825\n",
      "\t\tTEST AE-loss 0.063 \t AE-cor: 0.953\t cph-loss-avg: 0.059017 \t cph-cind: 0.686 [1101, 503, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1 600\t TRAIN AE-loss 0.053 \t AE-cor: 0.962\t cph-loss-avg: 0.020534 \t cph-cind: 0.824\n",
      "\t\tTEST AE-loss 0.062 \t AE-cor: 0.953\t cph-loss-avg: 0.059017 \t cph-cind: 0.685 [1098, 506, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1 700\t TRAIN AE-loss 0.053 \t AE-cor: 0.962\t cph-loss-avg: 0.020536 \t cph-cind: 0.823\n",
      "\t\tTEST AE-loss 0.062 \t AE-cor: 0.953\t cph-loss-avg: 0.059017 \t cph-cind: 0.684 [1097, 506, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1 800\t TRAIN AE-loss 0.053 \t AE-cor: 0.962\t cph-loss-avg: 0.020537 \t cph-cind: 0.823\n",
      "\t\tTEST AE-loss 0.062 \t AE-cor: 0.953\t cph-loss-avg: 0.059017 \t cph-cind: 0.682 [1094, 509, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1 900\t TRAIN AE-loss 0.052 \t AE-cor: 0.962\t cph-loss-avg: 0.020539 \t cph-cind: 0.822\n",
      "\t\tTEST AE-loss 0.062 \t AE-cor: 0.953\t cph-loss-avg: 0.059017 \t cph-cind: 0.68 [1090, 514, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1 1000\t TRAIN AE-loss 0.052 \t AE-cor: 0.962\t cph-loss-avg: 0.02054 \t cph-cind: 0.821\n",
      "\t\tTEST AE-loss 0.062 \t AE-cor: 0.954\t cph-loss-avg: 0.059033 \t cph-cind: 0.677 [1086, 518, 0]\n"
     ]
    }
   ],
   "source": [
    "for iter in 1:params_dict[\"nepochs\"]\n",
    "    ps1 = Flux.params(model[\"cph\"].model, model[\"enc\"])\n",
    "    gs1 = gradient(ps1) do\n",
    "        model[\"cph\"].lossf(model[\"cph\"],model[\"enc\"], train_x, train_y_e, NE_frac_tr, params_dict[\"cph_wd\"])\n",
    "    end \n",
    "    ## gradient Auto-Encoder \n",
    "    ps2 = Flux.params(model[\"ae\"].net)\n",
    "    gs2 = gradient(ps2) do\n",
    "        model[\"ae\"].lossf(model[\"ae\"], train_x, train_x, weight_decay = params_dict[\"ae_wd\"])\n",
    "    end\n",
    "    Flux.update!(model[\"cph\"].opt, ps1, gs1)\n",
    "    #Flux.update!(model[\"ae\"].opt, ps2, gs2)\n",
    "\n",
    "    ######\n",
    "    OUTS_tr = vec(model[\"cph\"].model(model[\"enc\"](train_x)))\n",
    "    ae_loss = model[\"ae\"].lossf(model[\"ae\"], train_x, train_x, weight_decay = params_dict[\"ae_wd\"])\n",
    "    ae_cor =  round(my_cor(vec(train_x), vec(model[\"ae\"].net(train_x))),digits = 3)\n",
    "    cph_loss = model[\"cph\"].lossf(model[\"cph\"],model[\"enc\"](train_x), train_y_e, NE_frac_tr, params_dict[\"cph_wd\"])\n",
    "    ae_loss_test = round(model[\"ae\"].lossf(model[\"ae\"], test_x, test_x, weight_decay = params_dict[\"ae_wd\"]), digits = 3)\n",
    "    ae_cor_test = round(my_cor(vec(test_x), vec(model[\"ae\"].net(test_x))), digits= 3)\n",
    "    cph_loss_test = round(model[\"cph\"].lossf(model[\"cph\"],model[\"enc\"](test_x), test_y_e, NE_frac_tst, params_dict[\"cph_wd\"]), digits= 3)\n",
    "                    \n",
    "    OUTS_tst =  vec(model[\"cph\"].model(model[\"enc\"](test_x)))\n",
    "            \n",
    "    cind_tr, cdnt_tr, ddnt_tr, tied_tr  = concordance_index(train_y_t, train_y_e, OUTS_tr)\n",
    "    cind_test,cdnt_tst, ddnt_tst, tied_tst = concordance_index(test_y_t, test_y_e,OUTS_tst)\n",
    "    if iter % 100 == 0  || iter == 1     \n",
    "        println(\"FOLD $(fold[\"foldn\"]) $iter\\t TRAIN AE-loss $(round(ae_loss,digits =3)) \\t AE-cor: $(round(ae_cor, digits = 3))\\t cph-loss-avg: $(round(cph_loss / params_dict[\"nsamples_train\"],digits =6)) \\t cph-cind: $(round(cind_tr,digits =3))\")\n",
    "        println(\"\\t\\tTEST AE-loss $(round(ae_loss_test,digits =3)) \\t AE-cor: $(round(ae_cor_test, digits = 3))\\t cph-loss-avg: $(round(cph_loss_test / params_dict[\"nsamples_test\"],digits =6)) \\t cph-cind: $(round(cind_test,digits =3)) [$(Int(cdnt_tst)), $(Int(ddnt_tst)), $(Int(tied_tst))]\")\n",
    "    end\n",
    "end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.4",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
